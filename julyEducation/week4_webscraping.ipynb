{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "- 특정한 목적으로 특정 웹 페이지에서 데이터를 추출하는 것 (데이터 추출)\n",
    "- 날씨 가져오기, 주식 데이터 가져오기 등\n",
    "\n",
    "# Web Crawling\n",
    "- URL을 타고다니며 반복적으로 데이터를 가져오는 과정 (데이터 색인)\n",
    "- 검색 엔진의 웹 크롤러"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 1. `Internet`, `WEB`, `HTTP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-(1). `Internet`과 `Web`\n",
    "### - `Network` : 두 컴퓨터를 연결하는 것\n",
    "### - 근거리 지역 네트워크 (`Local Area Network`) : Network를 묶음\n",
    "### - 범지구적 네트워크 `Internet` (Inter Network): LAN을 묶음\n",
    "### - `Web` (WWW : World Wide Web) : 인터넷에서 정보를 교환할 수 있는 환경(플랫폼)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-(2). `Web` 에서 정보를 주고받는 방법\n",
    "### 1. 클라이언트가 서버에게 정보를 요청\n",
    "### 2. 요청에 대해서 서버가 작업을 수행\n",
    "### 3. 수행한 작업의 결과를 클라이언트에게 응답\n",
    "\n",
    "### `! 이런 일련의 과정이 HTTP와 유사함 !`\n",
    "\n",
    "### 1. 클라이언트가 서버에게 정보를 요청 = `HTTP request`\n",
    "### 2. 요청에 대해서 서버가 작업을 수행\n",
    "### 3. 수행한 작업의 결과를 클라이언트에게 응답 = `HTTP response`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-(3). `HTTP` \n",
    "### - Hypertext Transfer Protocol (Hypertext가 오고가는 약속)\n",
    "### - 웹 상에서 정보를 주고받기 위한 약속\n",
    "### `1. HTTP에게 필요한 정보`\n",
    "### 요청/응답에 대한 정보를 담는 Head와 Body가 필요함\n",
    "### - `Head` : 보내는 사람, 받는 사람 등\n",
    "### - `Body` : 내용물"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "# 2. `WEB SITE`, `WEB PAGE`, `WEB BROWSER`, `HTML`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-(1). `WEB BROWSER` 역할을 `python`으로 대신 구현하기\n",
    "### - `웹 페이지`는 HTML (HyperText Markup Language)이라는 형식으로 되어있고, `웹 브라우저`는 우리가 HTTP 요청을 보내고, 응답받는 HTML 코드 렌더링을 해줌\n",
    "### - 이를 `python`으로 구현해 볼거임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 3. 웹 브라우저가 HTML을 다루는 방법\n",
    "## 3-(1). `DOM` (`Document Object Model`)\n",
    "### - 브라우저의 렌더링 엔진은 웹 문서를 로드한 후, `파싱`을 진행한다. (`파싱` : 웹 문서를 head, body 로 구분하고 각 태그와 속성들으 `DOM tree 형태`로 구성하는 과정) 이때의 형태를 DOM 이라고 한다.\n",
    "### - `브라우저가 DOM tree를 만들어내는 이유`는 각 태그와 속성들을 `객체`로 인식하여 사용하기 위해서이다. 각 HTML 요소들을 `객체`로 인식하면 브라우저에 내장되어있는 `JS`가 `동적으로 객체를 조작 혹은 find`할 수 있다.\n",
    "### - 따라서 `DOM Tree` 덕분에 `원하는 요소들을 find`할 수 있다.\n",
    "### - `Python`으로는 HTML을 분석하는 `HTML Parser`를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-(2). `HTML Parser` (`Request` + `BeautifulSoup4`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: requests in /opt/homebrew/lib/python3.9/site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.9/site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests) (2022.6.15)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 2em;\\n        background-color: #fdfdff;\\n        border-radius: 0.5em;\\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        div {\\n            margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get(\"http://www.example.com\")\n",
    "\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# BeautifulSoup 객체의 \n",
    "# 첫번째 인자는 response의 body를 텍스트로 전달\n",
    "# 두번재 인자는 'html'로 분석한다는 것을 명시\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Example Domain\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <style type=\"text/css\">\n",
      "   body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <h1>\n",
      "    Example Domain\n",
      "   </h1>\n",
      "   <p>\n",
      "    This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "   </p>\n",
      "   <p>\n",
      "    <a href=\"https://www.iana.org/domains/example\">\n",
      "     More information...\n",
      "    </a>\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Example Domain</title>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크래핑에 필요한 라이브러리 불러오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 디즈니 사이트 get\n",
    "res = requests.get(\"https://www.disneyplus.com/ko-kr/home\")\n",
    "\n",
    "# BeautifulSoup 객체 만들기\n",
    "disney = BeautifulSoup(res.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>디즈니+ | 디즈니, 마블, 픽사, 스타워즈, 내셔널지오그래픽이 모두 모인 곳</title>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney.find(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = disney.find_all(\"link\")\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<link href=\"https://edge.bamgrid.com\" rel=\"preconnect\"/>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preconnect']\n",
      "['preconnect']\n",
      "['preconnect']\n",
      "['preconnect']\n",
      "['preconnect']\n",
      "['manifest']\n",
      "['shortcut', 'icon']\n",
      "['mask-icon']\n",
      "['apple-touch-icon']\n",
      "['icon']\n",
      "['canonical']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['alternate']\n",
      "['stylesheet']\n"
     ]
    }
   ],
   "source": [
    "# 태그안 속성 불러오는 방법\n",
    "for link in links:\n",
    "    print(link[\"rel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id 이름으로 스크래핑하기\n",
    "disney.find(\"div\", id=\"webAppFooter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class 이름으로 스크래핑하기\n",
    "disney.find_all(\"div\", \"sc-jqIZGH iMngoM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf. 페이지마다 원하는 정보 모으는 방법 예시(= pagination)\n",
    "import time\n",
    "\n",
    "for i in range(1,6):\n",
    "    res = requests.get(\"디즈니 주소/?page={}\".format(i), user_agent) # {}안이 i로 치환된다.\n",
    "    disney = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    images = disney.find_all(\"div\", \"sc-jqIZGH iMngoM\")\n",
    "\n",
    "    for image in images:\n",
    "        print(image.find(\"div\", \"클래스 이름\").find(\"div\", \"클래스 이름\").h3.text)\n",
    "    \n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 4. `정적`, `동적 웹 사이트`와 지금까지의 `스크래퍼`의 문제점\n",
    "### - 웹 사이트는 `어떻게 생성`되냐에 따라서 크게 2가지로 구분된다. (`static`, `dynamic`)\n",
    "### - `static` : HTML 내용이 고정됨 (scraping이 쉬움)\n",
    "### - `dynamic` : HTML 내용이 변함 (지금까지의 scraping과 다른 방식으로 진행)\n",
    "### - JS는 비동기식 처리를 통해 웹 사이트를 구동한다.\n",
    "### - `동기식` : 요청에 따른 웅답을 기다린다. (렌더링 이후에 데이터 처리 가능)\n",
    "### - `비동기식` : 요청에 따른 응답을 기다리지 않는다. (렌더링 와중에 데이터 처리 가능 -> 지연 시간을 주어서 데이터를 가져오는 시간을 벌어주면서 scraping 진행)\n",
    "### `dynamic` + `비동기식` 처리 상황에서 우리는 `python을 이용하여 웹 페이지의 \"이벤트를 발생\"시키고 \"지연 시간을 발생\"시키면서 scraping`을 해야한다. (by. `Selenium`)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
