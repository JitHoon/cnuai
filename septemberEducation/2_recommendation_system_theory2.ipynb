{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 컨텐츠 기반 추천 엔진 개발 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Netflix Prize\n",
    "### 1-1) Netflix Prize 개요\n",
    "- 기념비적인 추천 엔진 경진 대회\n",
    "\n",
    "- 넷플릭스 추천 시스템 품질을 10% 개선하는 팀에게 상금 수요  \n",
    "\n",
    "- `RMS (Root Mean Square Error) 가 평가 기준`으로 사용됨\n",
    "\n",
    "- 이를 기폭제로 캐글과 같은 머신러닝 경진대회 플랫폼이 등장."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) Netflix Prize 우승팀과 알고리즘\n",
    "- 최종 우승팀 \"BellKor's Pragmatic Chaos\"\n",
    "\n",
    "- 이 대회를 통해 `협업 필터링이 한단계 발전`함\n",
    "\n",
    "- `SVD를 활용한 SVD++ (큰 행렬을 여러 작은 행렬의 곱으로 표현하고 비어있는 셀들을 ML 최적화 방식으로 채워나가는 알고리즘)`는 이후 굉장히 많은 분야에서 활용됨\n",
    "\n",
    "- `앙상블 방식의 모델 (여러 모델들을 조합한 방법)`들이 가장 좋은 성능을 보임 (너무 긴 실행시간 때문에 실제 프로덕션에서는 사용 불가)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3) `Ensemble`과 `Random Forest`\n",
    "- 다수 분류기를 사용해서 예측하는 방식\n",
    "\n",
    "- 성능이 좋지만 훈련과 예측 시간이 오래 걸린다는 단점 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고) 추천 엔진 발전 역사\n",
    "- `오토인코더` 기반 (복잡한 행렬 계산을 단순화하는 방식)\n",
    "\n",
    "- 아이템 관련 사용자 정보를 `시간순으로 인코드하는 RNN`을 사용하는 방식\n",
    "\n",
    "- `아마존에서 DSSNTE 라는 알고리즘을 오픈소스화` 했다가 `SageMaker 라는 제품`으로 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 유데미 추천 엔진 살펴보기\n",
    "- 학생들에게 관심있을 만한 강의를 먼저 보여주는 것\n",
    "\n",
    "- `하이브리드 방식 추천` : 협업 필터링, 사용자 행동 기반 추천, 머신러닝 모델기반 추천\n",
    "\n",
    "- 사용자별로 `등록 확률`을 기준으로 2천개의 탑 강의 목록 생성 (배치 -> 실시간 계산으로 변경)\n",
    "\n",
    "- `특정 강의 세부 페이지`에서 추천은 `아이템 중심` \n",
    "\n",
    "- ex 1) `student also bought (아이템 기반 협업 필터링)`\n",
    "\n",
    "- ex 2) `Frequently bought together (별도의 co-occurrence 행렬 계산)`\n",
    "\n",
    "- ex 3) `각 유닛`에서의 `강의 랭킹`은 `개인별 등록 확률`로 결정 \n",
    "\n",
    "- `사용한 추천 UI` : `격자 기반의 UI`\n",
    "\n",
    "- 온라인 강의의 `메타 데이터 요소` : 분류 체계, 태그, 클릭 키워드 분석 등\n",
    "\n",
    "- `행동 기반 추천 요소` : 클릭, 구매, 소비 등\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 인기도 기반 추천 개발\n",
    "- cold start(첫 사용자의 정보가 필요한 경우) 이슈가 존재하지 않음 (ex 현재 사용자들이 구매한, 보고 있는 아이템 추천)\n",
    "\n",
    "- `인기도 기준 : 평점, 매출, 최대 판매 등` (인기도의 기준에따라 다양한 추천 유닛 생성 가능)\n",
    "\n",
    "- `사용자 정보에 따라 확장 가능` : 서울 지역 인기 아이템 추천\n",
    "\n",
    "- `아이템의 분류 체계를 활용하여 쉽게 확장 가능` : 특정 카테고리에서의 인기 아이템 추천 (분류 체계를 가지고 있으면 인기도 기반 추천에 많은 도움이 된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![training](./pic/training.png)\n",
    "\n",
    "- `TMBD 데이터셋 (kaggle)` : 일반 사용자들이 영화정보를 수집하여 만든 DB\n",
    "- pandas, python\n",
    "- https://colab.research.google.com/drive/1K6O9YnHvNGqhm5flPl2tifEVhmMVZDp0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 유사도 측정 (`코사인 유사도`와 `피어슨 유사도` 설명)\n",
    "- `컨텐츠 기반에서 가장 중요한 부분`\n",
    "\n",
    "- 평점 기반(`협업 필터링 추천`)과 같은 사용자가 주는 데이터를 사용(개인화)하는 것이 아닌 아이템 정보 자체(`컨텐츠 기반 추천`)를 활용하여 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) `유사도 측정 알고리즘`\n",
    "- `벡터들간의 유사도를 판단하는 방법`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1-1) `코사인 유사도`\n",
    "- `방향성을 기준`으로 N차원 공간에 있는 `두 개의 벡터간의 각도를 보고 유사도를 판단`하는 기준\n",
    "\n",
    "- 완전히 같은 방향 0도 : 1\n",
    "- 90도 : 0\n",
    "- 완전히 다른 방향 180도 : -1\n",
    "\n",
    "![cos](./pic/cos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1-2) `피어슨 유사도 (보정된 코사인 유사도)`\n",
    "- 평점처럼 방향 뿐만 아니라 `벡터 크기의 정규화가 중요하면` 피어슨 유사도 사용\n",
    "\n",
    "- 코사인 유사도 계산식과 동일하게 사용 가능\n",
    "\n",
    "- 사용법 1. `벡터 A와 B의 값들을 보정` ex) 각 벡터내 셀들의 평균값을 구한 뒤 평균값을 각 셀에서 빼줌\n",
    "\n",
    "- 사용법 2. 정규화된 값을 `코사인 유사도 계산식에 대입`하여 계산\n",
    "\n",
    "- 장점 : 모든 벡터가 `원점을 중심으로 이동`되고 `벡터간의 비교가 더 쉬워`짐 (평점이라는 관점에서 까다로운 사용자와 아닌 사용자를 정규화하는 효과를 가져옴)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Count, TF-IDF 소개와 실습\n",
    "- `텍스트의 중요도를 측정하여 벡터로 표현`하는 기술\n",
    "\n",
    "- 워드 임베딩(딥러닝)이 가장 진보된 형태임 (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1) `원핫 인코딩 + Bag of Words (count)` (텍스트 -> 행렬)\n",
    "\n",
    "![count](./pic/count.png)\n",
    "\n",
    "- 위는 사용된 단어를 원핫-인코딩으로 나타낸 뒤 `단순 카운트`하여 벡터로 가져온 경우 (자주나오는 단어가 높은 가중치를 갖게 됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사이킥 런에서 제공하는 `CountVectorizer` 사용\n",
    "- 앞선 `원 핫 인코딩 + count 방식`을 구현한 모듈\n",
    "\n",
    "![CountVectorizer](./pic/CountVectorizer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2) `원핫 인코딩 + Bag of Words (TF-IDF)` (텍스트 -> 행렬)\n",
    "\n",
    "- TF-IDF 까지 사용하는 경우 `원핫 인코딩으로 단어를 표현한 후 텍스트의 중요도를 측정하여 벡터로 나타낸다.`\n",
    "\n",
    "#### `TF-IDF 기본 아이디어`\n",
    "- 한 문서에서 중요한 단어를 카운트가 아닌 `문서군 전체를 보고 판단`\n",
    "\n",
    "- 어떤 단어가 한 문서에서 자주 나오면 중요하지만 `이 단어가 다른 문서들에서는 자주 나오지 않는다면 더 중요 (각 문서군에서 적게 나올수록 IDF 값이 올라감)`\n",
    "\n",
    "![idf](./pic/idf.png)\n",
    "\n",
    "![tfidf](./pic/tfidf.png)\n",
    "\n",
    "- , 의 왼쪽 숫자 : TF-IDF 방식일 때 가중치\n",
    "\n",
    "- , 의 오른쪽 숫자 : count 방식일 때 가중치\n",
    "\n",
    "- 4/3 : 4개의 문서중에 3개의 문서에서 단어가 나옴\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사이킥 런에서 제공하는 `TfidVectorizer` 사용\n",
    "\n",
    "![tfidv](./pic/tfidv.png)\n",
    "\n",
    "- DOC1의 값들을 제곱하여 더한 후 루트를 씌우면 1이된다.\n",
    "\n",
    "- DOC1과 DOC2는 겹치는 단어가 없으므로 유사도가 0이다.\n",
    "\n",
    "- tfidf의 경우 text가 동일하냐 아니냐로 따지기 때문에 각 단어간 벡터 유사도를 확인할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tfidv2](./pic/tfidv2.png)\n",
    "\n",
    "- 문서들간의 유사도를 나타내는 행렬을 선언하여 검사\n",
    "\n",
    "- 유사도가 크게 나오는 순서대로 정렬을 하여 추천하면 컨텐츠 추천 알고리즘이됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TF-IDF 문제점`\n",
    "- 정확히 동일한 단어가 나와야 유사도 계산이 이뤄짐 (`동의어 처리가 안됨`)\n",
    "\n",
    "- 단어의 수가 늘어나고 아이템의 수가 늘어나면 `계산이 오래걸림`\n",
    "\n",
    "- 결국 `워드 임베딩`을 사용하는 것이 더 좋음\n",
    "\n",
    "- 혹은 `LSA (Latent Semantic Analysis)` 와 같은 `차원 축소 방식` 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`원핫 인코딩 + Bag of Words (count or TF-IDF) 코랩 실습`\n",
    "https://colab.research.google.com/drive/1WRd0uhPSwLVuQk998teEaziCHesMNawD?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TF-IDF를 이용한 컨텐츠 기반 추천 엔진 실습 (with TMDB (영화 데이터 베이스))\n",
    "https://colab.research.google.com/drive/1xbFjBvzgiDpPwBwKiaMw0ByWos12EAiD?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas, numpy with kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![summary](./pic/summary.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
