{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 다층 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가장 기본적인 단위인 \n",
    "\n",
    "`퍼셉트론` (인공두뇌학 `cybernestic`) \n",
    "\n",
    "-> `다층 퍼셉트론` (결합설 `connectionism`) \n",
    "\n",
    "-> `깊은 인공신경망` (심층학습 `deep learning`) \n",
    "\n",
    "순서로 살펴봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 사람의 뉴런 (`neuron`)과 `퍼셉트론`\n",
    "< `neuron` : `두뇌의 가장 작은 정보처리 단위` >\n",
    "\n",
    "- 구조 : 세포체 (`연산`), 축삭 (`전송`), 수상돌기 (`수신` (정보를 받음))\n",
    "\n",
    "- 뇌의 정보처리를 컴퓨터 계산 (연산) 능력으로 모방하여 인공 신경망의 기초 단위인 `퍼셉트론`을 고안\n",
    "\n",
    "< `퍼셉트론` : `인공 신경망의 기초 단위` >\n",
    "\n",
    "- 구조 : 절 (`node`), 가중치 (`weight`), 층 (`layer`)\n",
    "\n",
    "- 깊은 인공신경망을 포함한 현대 인공신경망의 토대"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neuron](./pic/neuron.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![perceptron](./pic/perceptron.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 전방(`forward`), 순환(`recurrent`), 얕은(`shallow`), 깊은(`deep`) 신경망\n",
    "\n",
    "![models](./pic/models.png) \n",
    "\n",
    "- 은닉층 (네트워크)의 구조가 크냐 작냐로 깊이를 구분\n",
    "- 깊은 신경망이 얕은 신경망 보다 가중치가 더 많기 때문에 모델 cap이 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 결정론(`deterministic`), 확률론적 (`stochastic`) 신경망\n",
    "- `결정론` : 모델의 매개변수와 조건에 의해 출력이 완전히 결정되는 신경망\n",
    "\n",
    "- `확률론적` : 고유의 `임의성`을 가지고 매개변수와 조건이 같더라도 다른 출력을 가지는 신경망 (`불확실성을 고려함`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![models2](./pic/models2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `퍼셉트론의 구조`\n",
    "- 크게 절 (`node`), 가중치 (`weight`), 층 (`layer`) 로 구성되고 입력, 입출력 연산, 출력 구조에 포함되어있다.\n",
    "\n",
    "1. `입력` : 특징 벡터 x 입력을 node를 통해 받음, 항상 1이 입력되는 `bias node` 포함 (`bias node` : 임게치 `T`의 위치를 원점으로 맞춰주는 역할)\n",
    "\n",
    "\n",
    "2. `입출력 연산 구조` : 입력 노드와 축력 노드를 연결하는 `edge에 weight (가중치 w)를 가짐` (퍼셉트론은 단일 층 구조로 간주)\n",
    "\n",
    "\n",
    "3. `출력` : 한 개의 노드에 의해 수치 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. `퍼셉트론의 동작`\n",
    "- `선형` 연산 -> `비선형` 연산\n",
    "\n",
    "- `선형` 연산 : 입력과 가중치의 `내적` (합과 곱, `내적` : `입력이 가중치와의 방향성이 유사할수록 (유사도가 높을수록) 큰 값이 나옴!`)\n",
    "- `비선형` 연산 : 활성함수 타우를 적용 (`가중치에 따른 1과 -1 출력`)\n",
    "\n",
    "![perceptron3](./pic/perceptron3.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](./pic/example.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래는 퍼셉트론 동작중 `임계치의 직선화 및 기하학적 해석`이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![perceptron4](./pic/perceptron4.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 일반적인 분류기의 학습 과정 (그래서 학습은 어떻게?)\n",
    "1. 과업 정의와 분류과정의 수학적 정의 (`가설 설정` (퍼셉트론))\n",
    "\n",
    "2. 해당 분류기의 `목적함수 J(세타) 정의` (손실 함수이므로 클수록 학습이 좋지 않음)\n",
    "\n",
    "3. `J(세타)를 최소화하는 세타를 찾기` 위한 최적화 방법 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Jdefine](./pic/Jdefine.png) \n",
    "![makeJ](./pic/makeJ.png) \n",
    "![findJ](./pic/findJ.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론의 학습 방법인 `가중치 갱신 규칙`을 활용한 `델타 규칙`을 사용하기 위해서 목적함수를 편미분한 경사도 g가 필요하다.\n",
    "\n",
    "- 이때 로 (학습률 `learning rate`)는 얼만큼 방향을 수정할 지 결정하는 길이(거리, step)이라고 해석하면 된다.\n",
    "\n",
    "![g](./pic/g.png) \n",
    "\n",
    "- 아래는 퍼셉트론의 학습 방법중 하나인 `델타 규칙`이다.\n",
    "\n",
    "![rule](./pic/rule.png) \n",
    "\n",
    "- 예시를 보면 틀린 샘플로 인해 가중치가 갱신된다. 이 가중치들의 합 벡터에 직교하는 직선을 그으면 가중치가 반영된 결정 직선을 만들 수 있다. 결과적인 관점에서 새로운 결정 직선은 틀린 샘플과 직선의 중점을 기준으로 뒤집힌 직선으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![deltaex](./pic/deltaex.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
