{"cells":[{"cell_type":"markdown","metadata":{},"source":["# `컨볼루션 신경망의 기초와 PyTorch에서의 AlexNet 모델 실습 적용`"]},{"cell_type":"markdown","metadata":{},"source":["![DMLPCNN](./pic/DMLPCNN.png)"]},{"cell_type":"markdown","metadata":{},"source":["![conv](./pic/conv.png)"]},{"cell_type":"markdown","metadata":{},"source":["![stridepadding](./pic/stridepadding.png)"]},{"cell_type":"markdown","metadata":{},"source":["![pooling](./pic/pooling.png)"]},{"cell_type":"markdown","metadata":{},"source":["![str](./pic/str.png)"]},{"cell_type":"markdown","metadata":{},"source":["- 실습에서 살펴볼 `AlexNet 모델`은 2012년도에 높은 정확도 개선을 보여준 대표적인 모델이다.\n","\n","- `8개의 계층 구조`\n","- `ReLU 함수`를 사용한 첫 모델\n","- fully connected layer층에 `drop out 기법`을 사용\n","- `max pooling 기법` 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3G6N4VQkDkD","vscode":{"languageId":"python"}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from .utils import load_state_dict_from_url\n","from typing import Any\n","\n","\n","__all__ = ['AlexNet', 'alexnet']\n","\n","\n","model_urls = {\n","    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n","}\n","\n","\n","class AlexNet(nn.Module):\n","\n","    def __init__(self, num_classes: int = 1000) -> None:\n","        super(AlexNet, self).__init__()\n","\n","        # nn.Sequential : layer 쌓는 곳 (5개의 conv와 3개의 pooling)\n","        # 모델의 특징 추출 부분에 해당함\n","        self.features = nn.Sequential(\n","\n","            #Conv1\n","            #input channel : 3 , output channel : 64, kernel_size : 11*11, stride : 4, padding : 2\n","            \n","            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n","            nn.ReLU(inplace=True), # inplace=True 하면, inplace 연산을 수행함, inplace 연산은 결과값을 새로운 변수에 값을 저장하는 대신 기존의 데이터를 대체하는것을 의미\n","            #Max Pool1\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            #Conv2 이젠 아웃풋 채널과 동일한 인풋 64\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            #Max Pool2\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            #Conv3 \n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            ##Conv4\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            #Conv5\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            #Max Pool3\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )\n","\n","         # average pooling 연산 진행\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        \n","        # 모델의 분류증에 해당함\n","        self.classifier = nn.Sequential(\n","\n","            #드롭아웃 \n","            nn.Dropout(),\n","            # fully connected layer1 : 차원 256*6*6 아웃풋 4096\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","\n","            # fully connected layer2 : 이전 아웃풋 = 인픗 4096\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","\n","            # fully connected layer3 (최정 분류층)\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    # 이미지 데이터 (x)가 들어왔을 때 거치는 layer들 선언\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        # 위 특징 추출 부분 layer\n","        x = self.features(x)\n","       \n","        # average pooling 부분 layer\n","        x = self.avgpool(x)\n","        #output shape : (batch size * 256(channel), 6, 6)\n","        \n","        # Flatten layer : 격자 모양의 특징맵을 한 줄로 펼쳐주는 layer\n","        x = torch.flatten(x, 1)\n","        #output shape (batch_size, 256 * 6* 6)\n","        \n","        # 분류 layer \n","        x = self.classifier(x)\n","        return x\n","\n","# 1. \n","# pytorch에서 구현될 모델 함수(alexnet)를 호출할 때 사용하는 def\n","# pretrained : 사전 학습된 모델을 가져올지말지 결정하는 불리안 인자\n","def alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> AlexNet:\n","    r\"\"\"AlexNet model architecture from the\n","    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","\n","    # 모델에 알렉스넷 모델 함수를 넣어주면ㅅ 시작한다!\n","    model = AlexNet(**kwargs)\n","    if pretrained:\n","        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n","                                              progress=progress)\n","        model.load_state_dict(state_dict)\n","    return model"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM2fGN8fNeTZyzrGvTdFFV5","collapsed_sections":[],"name":"AlexNet_model(Pytorch).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
