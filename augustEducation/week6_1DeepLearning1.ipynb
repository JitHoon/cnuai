{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 인공지능 개요\n",
    "- 인간처럼 생각하고 행동하는 기기 (by, 컴퓨터 프로그래밍)\n",
    "- 이번 수업에서는 `학습`이라는 관점(`머신러닝`)에서 인공지능을 바라본다.\n",
    "- `머신러닝` 중에서도 하나의 학습 방법인 `Deep Learning`에 대해서 알아봄\n",
    "- ex) 음성인식, 추천 시스템, 자율주행, 실시간 객체 인식, 로봇, 번역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인공지능 시작 (1940~) -> 기계학습 (1980~) -> 심층학습 (~2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `데이터` 분석을 기본 소양으로 가져가고 `python`과 `open source`로 `인간중심`의 소통해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `신경망`은 레고처럼 `조립이 가능`하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ai_framework](./pic/ai_framework.png)\n",
    "![compare_framework](./pic/compare_framework.png)\n",
    "- ai framework (실습은 `pytorch`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# 2. 인간 학습 vs 기계 학습\n",
    "- 이번 내용 : 기계도 학습이 가능한가? -> 가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1) 기계 학습\n",
    "- 초창기 정의 : `경험` = `데이터` 를 통해 배우는 컴퓨터 프로그램\n",
    "- 현대적 정의 : `경험` = `데이터` 를 통해 성능이 개선되는 프로그램 ( `경험 E` * `작업 T` = `성능 P`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input(`data`)과 `원하는 결과`를 기계에 입력하여 기계가 `스스로 규칙을 찾아` 원하는 결과를 내놓도록 하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인공지능의 탄생 = 연산 장치의 탄생\n",
    "- 초창기 지식 기반(rule base) 가계 학습이 주류였음\n",
    "- 지식 기반 -> 기계 학습 -> 심층 학습 (표현 학습 (데이터 중심 학습))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-1) 기계 학습 예제 (E * T = P)\n",
    "- 가로축은 시간, 세로축은 이동체의 위치일 때 4개의 점이 있다. (벡터 형테의 `data` = `경험 E` = 관찰된 데이터) 이때 임의의 시간이 주어지면 이동체의 위치 (`작업 T`) 는?\n",
    "- `예측(성능) P` : `회귀(regression)`와 `분류 (classification)`로 나뉨. `회귀(regression)`는 목표치가 `실수`의 값, `분류 (classification)`는  `종류`의 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-2) 훈련 집합 (training set(data))\n",
    "- : `경험`(= data, 규칙이 내제된 값)을 통해서 `규칙을 찾는 학습`을 위한 `훈련용 데이터` = `입력값`(= x값, 특징)과 그에 대응하는 `출력값` (= y값, 목표값, 라벨값)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-3) 관찰된 데이터들을 어떻게 설명할 것인가?\n",
    "- `가설` : 모델을 특정 식으로 선택 가정\n",
    "- 위의 예제의 경우 2개의 매개변수를 사용하여 직선 방정식을 가정으로 선택\n",
    "- deep learnig이 강력한 이유는 가설이 불완전하여도 예측을 잘 수정해주기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-4) 기계 학습의 훈련\n",
    "- 주어진 문제 예측(기설)을 가장 정확하게 할 수 있는 `최적의 매개변수를 찾는` 작업 (with 훈련 집합)\n",
    "- `임의의 매개변수` 값에서 시작하지만, 개선하여 `정량적인 최적 성능`에 도달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-5) 좋은 예측의 정량적 판단은??\n",
    "- error를 통해 서로 다른 예측과 비교 및 판단."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-6) 훈련을 마치면 추론(inference)을 수행\n",
    "- : `새로운 특징`(관찰된 데이터 이외의 예측으로 얻는 값들)에 대응되는 `목표치의 예측`(= 추론)을 수행하는 것\n",
    "- `새로운 데이터들`(= 테스트 집합)을 `예측식`에 넣어서 새로운 지점에서의 값을 추론 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-7) 기계 학습의 궁극적인 목표\n",
    "- 훈련 집합에 없는 `새로운 데이터`(= 테스트 집합, 보지못한 데이터)에 대한 `오류를 최소화`\n",
    "- 테스트 집합에 대한 높은 성능을 `일반화(generalization) 능력`이라고 부름\n",
    "- ex) 모의고사만 잘 본 학생 vs 모의고사와 수능을 잘 본 학생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-8) 기계학습의 필수요소\n",
    "- 1. `학습`할 수 있는 `데이터`\n",
    "- 2. 데이터 `규칙` 존재\n",
    "- 3. `수학적으로 설명 불가능`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2) 특징 공간의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1) 특징 공간\n",
    "- 모든 데이터는 정량적으로 표현되고 특징 공간 상에 존재\n",
    "- `1차원 특징 공간`\n",
    "- `2차원 특징 공간` : 특징 벡터로 표기 (`각 차원`들이 의미하는 것 : 어떤 `각 입력에 대해`서 서술하고 있는 `특징`)\n",
    "- `다차원 특징 공간` : 4차원 (Iris), 16차원 (MNIST 4*4 화소)\n",
    "- 이러한 데이터의 특징 공간안에서 규칙을 찾음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `d-차원 데이터` : 컴퓨터가 이해할 수 있도록 공간상에 `d-차원의 벡터`로 표현\n",
    "- ex) y = w1x1 + w2x2 + w3x3 + ... (매개변수 수 d+1): `1차원의 벡터 표현에서 학습으로 매개변수 w를 결정하여 y를 예측`, 2차원의 경우 매개 변수 수  : d^2 + d + 1 -> 예측 모델의 차원에 따라서 필요한 매개 변수 수가 달라짐\n",
    "- `거리` : 차원과 무관하게 수식 적용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 차원의 저주 : 차원이 높아짐에 따라 발생하는 현실적인 문제들 -> 차원이 높아질수록 유의미한 표현을 찾기위해 지수적으로 많은 데이터가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특징 공간 중 선형 분리가 불가능한 공간이 존재함 ex) 흩어져있는 2차원의 4개의 점에대해서 직선 모델로 풀이하기에는 무리가 있음\n",
    "- 하지만 새로운 공간 좌표에서의 예측 모델로 데이터들을 새롭게 표현할 수 있으며 이를 `표현 문제`라고 부른다.\n",
    "- `표현 문제`중 하나인 `심층 학습`은 다수의 은닉층을 가진 `신경망`을 이용하여 `최적의 계층적인 특징`을 학습하는 것이다.\n",
    "- 또한 주어져있는 데이터의 공간을 통해서 규칙을 찾는 것이 `표현 학습`이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `AI` : 인간의 지능을 모방하는 기술들\n",
    "#### `ML`(기게 학습) : 문제(데이터)에대한 규칙을 찾아 학습하는 기술\n",
    "#### `Representation Learning` (표현 학습) : 특징 공간 안에서 표현되는 공간적인 규칙들을 찾아서 학습하는 기술 (classic은 사람이 개입, RL은 데이터가 개입)\n",
    "#### `Deep Learning` (심층 학습) : 특징 공간들을 신경망을 통해서 좀 더 계층화되어있는 representation 되어있는 데이터를 학습하는 기술 : 현대 인공지능 실현에 핵심 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# 3) 데이터에 대한 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1) 데이터와 기계학습\n",
    "- `데이터를` 단순한 수학 공식이 아닌 `학습 모델로 설명`하는 과정\n",
    "- 따라서 데이터를 `수집`하고 `전처리`하는 과정도 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2) 데이터 생성 과정을 알 수 없는 기계 학습\n",
    "#### `기계 학습은 수학적으로 표현할 수 없는 규칙을 찾는 행위`\n",
    "- `데이터 생성 과정을 완전히 아는 경우`(주사위) 확률 통계의 문제이며 기계 학습의 범주는 아니다.\n",
    "- 따라서 실제 기계 학습 문제는 `데이터 생성 과정을 알 수 없다.`\n",
    "- 기계 학습은 `규칙을 알 수 없는 훈련집합`에서 `가설 모델`을 통해 `근사 추정`만 가능하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 : 공개 데이터 : Iris, MNIST, ImageNet, UCI 저장소\n",
    "- MNIST : 28*28 픽셀에 흑백 정보로 구성 -> 서로 다른 총 샘플(공간) 수 2^784 개로 존재할 수 있지만 MNIST의 데이터는 6만개만 존재하므로 `데이터가 적다`고 할 수 있다.\n",
    "- 그럼에도 불구하고 MNIST의 성능은 좋다.(= `하지만 적은 데이터 셋(6만)으로도 규칙을 잘 찾는다.`)\n",
    "- 그 이유는 1. `데이터 희소 특성` : 방대산 공간(2^784)에서 `실제 데이터가 발생하는 곳은 매우 작기 때문`\n",
    "- 2. `매니폴드 가정` : 고차원의 데이터에서 나타나는 규칙이 저차원에서도 보존된다는 가정. (고차원의 데이터를 `저차원으로 가져와 정보의 양을 줄일 수 있기 때문`)\n",
    "\n",
    "#### `즉 규칙은 모든 공간에서 발현되는 것이 아니고 부분적인 공간에서만 발생한다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3) 기계 학습의 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3-1) `선형 회귀` (linear regression) 문제 (y값이 종류 = 분류 문제, `y값이 연속 = 회귀 문제`)\n",
    "- ![ML_example](./pic/ML_example.png)\n",
    "- w, b 매개변수를 찾는 과정\n",
    "- 경험(데이터)을 통해 과업을하고 성능을 향상시키는 기계 학습에서 `판단 기준이 되는 함수`를 `목적 함수`(objective function) 혹은 `비용 함수`(cost function)라고 한다.\n",
    "- 아래는 선형 회귀를 위한 목적 함수(`성능 판단 기준`)인 `MSE`이다. (오차가 낮아지게 모델과 가설을 만들고 세워야한다.)\n",
    "- ![mean_squared_error](./pic/mean_squared_error.png)\n",
    "- ![find_w_b](./pic/find_w_b.png)\n",
    "- w, b의 갱신은 차후에 살펴볼 예정\n",
    "- 선형 회귀 문제와 같이 `최적해가 하나`인 경우 `convex 방법`으로 최적화를 진행한다. (최적해가 존재하지 않거나 찾기 어려운 신경망의 경우 `non-convex 방식`(그레디언트 디센트 : 기울기가 0일 때 오차가 최소인 점을 찾는 방식)으로 최적화를 진행한다.)\n",
    "#### `기계 학습`은 `작은 개선을 반복`하여 `최적의 해`를 찾아가는 수치적 방법으로 아래 식을 푸는 것이다.\n",
    "- ![optimize_solution](./pic/optimize_solution.png)\n",
    "- 오차 J(세타)의 최소값을 갖는 세타를 찾는 과정임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3-2) `분류` (classification) 문제 (y값이 종류 = 분류 문제)\n",
    "- 카드 승인, 비승인 문제 (카드를 승인하냐 안하냐 분류를하는 문제)\n",
    "- ![classification_problem](./pic/classification_problem.png)\n",
    "- 위와 같은 `교사학습`(x와 y의 관계를 unknown target Distribution 에의해서 생성이되는 f (target function)를 찾는 학습 = 몇개의 답을 알려주고 나머지를 맞추는 학습)의 경우 아래 그림과 같이\n",
    "- `Traning Example`의 `Input`으로 `Unknown target Distribution`(입력에의한 출력 생성 규칙)과 `Unknown Input Distribution`(입력의 분포)을 넣고 `목적 함수`를 통해 `성능을 판단`하여 `최적화` 하는 과정을 거친다.\n",
    "- ![supervised_Learning_process](./pic/supervised_Learning_process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3-3) 실제 세계 데이터와 `비선형 모델`\n",
    "- 실제 세계에서는 데이터에 `잡음`이 섞이므로 `비선형 모델`이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 4) 모델 결정 (가정 설정)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) `과소적합`(underfitting)과 `과잉적합`(overfitting)\n",
    "- `과소적합`(underfitting) : 주로 1차 모델이 과소적합이며 모델의 `용량이 작아 오차가 클` 수밖에 없는 현상. (모델이 데이터를 못 따라감)\n",
    "- 대안 : `비선형 모델`을 사용하여 1차 모델에서의 오차를 많이 줄일 수 있음\n",
    "- `과잉적합`(over fitting) : `용량이 너무 커서` `잡음까지 수용`하는 현상. (모델이 잘못된 데이터까지 학습함) -> 12차 모델의 경우 훈련 데이터에 대해서는 거의 완벽하게 근사화한다. 하지만 `새로운 데이터` 예측에서 문제가 발생한다.\n",
    "- 위와 같은 현상 때문에 적절한 용량의 모델을 선택하는 `모델 선택 작업`이 필요하다.\n",
    "- 데이터에 적합한 모델을 선택하기 위해서는 `Underfitting zone`과 `Overfitting zone` `각 zone에서 발생하는 error`와 `Training error의 차이`인 `Generalization error`(일반화 능력)가 `가장 적은 모델로 결정`한다.\n",
    "- ![optimal_capacity](./pic/optimal_capacity.png)\n",
    "- 이에따라 현대 DL 전략으로 `용량이 큰 모델을 선택해 놓고 여러 규제를 걸어서 데이터에 맞는 모델`을 만드는 `규제 방식`(regularization)을 사용하여 모델을 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2) `편향`(bias)과 `분산`(variance)\n",
    "- `저차` 모델의 경우 `편향은 크고 분산은 낮다.` (`편향` : 원래 값과 `다른 정도`, `분산` : 모델 예측의 `변동성`(여러번의 훈련 집합에 대해서 그래프 모양이 거의 바뀌지 않음))\n",
    "- `고차` 모델의 경우 `편향은 작고 분산은 높다.` (잘 맞추지만 규칙이 자주 바뀜)\n",
    "- 편향과 분산은 `trade off 관계`에 있다.\n",
    "- 따라서 기계 학습의 목표는 `낮은 편향`과 `낮은 분산`을 가지는 예측 모델을 만드는 것이다.\n",
    "- ![bias_variation](./pic/bias_variation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3) `검증 집합`(validation setvalidation setvalidation set)을 이용한 모델 선택 (데이터 양이 많을 때 사용)\n",
    "- : `트레이닝 집합`에 `검증집합`(validation set)을 추가하여 `일반화 성능`(Generalization Error)을 측정하여 모델을 선택하는 방식\n",
    "- ![validation_set](./pic/validation_set.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4) `교차 검증`(cross validation)을 이용한 모델 선택 (데이터 양이 적을 때)\n",
    "- 각 variation에 대해서 검증하는 방식\n",
    "- ![validation](./pic/validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-5) `부트스트랩`(bootstrap)을 이용한 모델 선택 (데이터 분포가 불균형일 때)\n",
    "- data set에서 임의로 `복원 추출 샘플링을 반복`하여 훈련 데이터로 활용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +) `데이터 수집`과 `데이터 확대`을 통한 모델 개선\n",
    "- `데이터가 많을수록 일반화 능력이 향상됨` (12차의 경우 분산도 낮아짐)\n",
    "- 하지만 데이터를 많이 모으기에는 `비용이 많이듦` -> 주어진 데이터를 활용하여 인위적으로 `데이터 확대` (data agmentation) (약간의 회전 도는 왜곡을 통해 데이터를 확대한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +) `가중치 감쇠` (규제 기법 중 하나)를 통한 모델 개선\n",
    "- 개선된 `목적함수를 이용`하여 `가중치(매게 변수 값)를 작게 조절`하는 규제 기법 (목적 함수(푱균제곱오차)항에 규제 항을 추가하여 제어)\n",
    "- ![regulation](./pic/regulation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +) 지도 방식에 따른 기계 학습 유형\n",
    "- `지도 학습` (supervised learning) : 특징 벡터 x와 목표치 y가 모두 주어진 상황 (`회귀`, `분류` 두 문제로 구분)\n",
    "- `비지도 학습` (unsupervised learning) : 특징 벡터 x는 주어지는데 목표치 y가 주어지지 않는 상황 (`군집화 과업`(고객 성향에 맞는 맞춤 홍보), `밀도 추정`, `특징 공간 변환` (PCA) 등)\n",
    "- `강화 학습` (reinforcement learning) : (상대적) 목표치 (= 상황에 따라 결과가 다른 경우)가 주어지는데, 지도 학습과 다른 형태 (`보상`)\n",
    "- `준지도 학습` (semi-supervised learning) : 일부만 x, y를 가지고 일부는 x만 가지는 상황 (y가 수작업이 필요하여 최근 중요성 부각)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
