{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 인공지능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 평균제곱 오차 (MSE) 목적함수\n",
    "$ e = 1/2 |y-o|^2 $\n",
    "- 오차가 클수록 e값이 크므로 벌점으로 활용\n",
    "\n",
    "- 하지만 큰 `허점`이 존재함 : 학습은 오류를 줄이는 방향으로 가중치와 편향을 교정하지만 MSE 사용후 back propagation을 적용하면 `오류가 커도 경사도(=벌점)가 작게 계산되어 작게 계산되는 경우가 발생`한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mse](./pic/mse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이에따라 목적함수를 MSE에서 `cross entropy (교차 엔트로피)`로 바꾸어 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. `Cross entropy`\n",
    "\n",
    "- P는 정답, Q는 신경망 (예측) 출력일 때, P의 출력은 0 혹은 1, Q의 출력은 binary property의 확장으로 o 혹은 1-o로 보고 `P, Q의 서로 다른 RV간의 상관 관계(불확실성)를 교차 엔트로피를 통해 확인.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![crosse](./pic/crosse.png)\n",
    "\n",
    "- cross entropy를 통해 오차가 클수록 벌칙도 더 크게 줄 수 있게됨\n",
    "\n",
    "![crosse1](./pic/crosse1.png)\n",
    "\n",
    "- c개의 출력노드로 확장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross entropy 를 사용했을 때의 `output gradient * local gradient`\n",
    "\n",
    "![cross](./pic/cross.png)\n",
    "\n",
    "- MSE vs cross entropy \n",
    "\n",
    "![vsmse](./pic/vsmse.png)\n",
    "![vscross](./pic/vscross.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. `softmax 함수`\n",
    "- `출력 노드의 중간 계산 결과의 최댓값을 더욱 활성화하고 작은 값들은 억제`하는 함수 (모두 더하면 1이 되는 확룰 모방)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![softmax](./pic/softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cross entropy + softmax 목적함수 연산 과정`\n",
    "![cs](./pic/cs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`softmax + 로그우도` 목적함수\n",
    "\n",
    "- `예측값이 틀린` 경우 : `softmax 후 결과값이 정답인 예측값보다 작기 때문에 로그우도 식에 대입했을 때 목적함수(로스, 벌칙)의 크기가 큰 값으로 출력이된다.` 따라서 softmax와 로그우도는 자주 함께 쓰인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![solo](./pic/solo.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
